### **[The IEC 61499 Function Block Standard: Overview of the Second Edition](https://www.researchgate.net/publication/235225081_The_IEC_61499_Function_Block_Standard_Overview_of_the_Second_Edition)**
*Christensen, J. H., Strasser, T. I., Valentini, A., Vyatkin, V., Zoitl, A.*
*ISA Automation Week, 2012.*


s(ections capitalized like the case in the paper under discussion)  
1. Existing standards covered two main worlds:

* **IEC 61131-3**
  → **centralized, cyclic-scan PLCs**
  → Widely deployed, but poorly suited for distributed, event-driven systems.

* **IEC 61804** (late 1990s / early 2000s)
  → **Distributed Control Systems (DCS)** with scheduled execution

IEC 61499 was designed to be **mappable to both domains**, while also allowing a **purely event-driven, distributed execution model**.

2. Between **1996 and 2000**, the **Holonic Manufacturing Systems (HMS) Consortium** carried out geographically distributed implementation projects to test whether IEC 61499 was practically viable. These experiments exposed the need for **Compliance Profiles**, introduced to ensure interoperability across tools and vendors.

3. Initially, IEC 61499 was published as **Publicly Available Specifications (PAS)** and a **Technical Report (TR)**. Based on implementation experience, it was elevated to a full IEC standard in **2005**, consisting of:

* **IEC 61499-1** – Architecture
* **IEC 61499-2** – Software tool requirements
* **IEC 61499-4** – Rules for compliance profiles

(**IEC/TR 61499-3**, containing tutorial material based on the PAS versions, was later withdrawn in **2007**.)

After several years of real-world use, ambiguities—particularly in **execution semantics and Execution Control Charts (ECCs)**—became evident => **Second Editions of Parts 1, 2, and 4 in 2012**.

---

## 1. Function Block (FB) type = the atom

According to **IEC 61499-1**, the Function Block type is the **basic reusable unit**.

* An FB **type** is like a **class** (OO analogy).
* We can instantiate it many times.
* It encapsulates:

  * **Event inputs/outputs**
  * **Data inputs/outputs**

* Events **synchronize data movement and execution**
* Essential in **distributed systems**, where “who runs when” is not trivial.

(break from classic PLC thinking=.

---

### 2. Basic Function Blocks = executable atoms

A **Basic FB** contains:

* Algorithms (the actual code)
* An **Execution Control Chart (ECC)**

These ECCs are:

* Event-driven **state machines**
* Very similar to **Harel Statecharts**, i.e., not regular FSMs.
* They decide **which algorithm runs when**
(*Harel Statecharts*: designed to scale to real systems.: hierarchicay (state nesting instead of flat states), Concurrency (orthogonal regions) model things happening in parallel, event-driven (transitions are triggered by events, optionally guarded by conditions and actions))

* Algorithms can be written in:

  * **IEC 61131-3 languages**
  * Or C / C++ / Java

(IEC 61131-3 programming languages: **5** PLC programming languages. These are *the* canonical ones:

Ladder Diagram (LD), Function Block Diagram (FBD), Structured Text (ST), instruction List (IL), Sequential Function Chart (SFC)

IEC 61131-3 defines: syntax, semantics, execution model, data types, program organization units (POUs).

### 3. Service Interface Function Blocks (SIFBs) = the glue to reality
**atomic FB type**, but they don’t do logic; SIFBs are **contracts**, not algorithms and they describe *how* the software talks to:
* networks
* hardware
* OS
i.e., interface to low­level services provided by the operating system or hardware of the embedded device,
Often documented using **service sequence diagrams**.

### 4. Composite Function Blocks = molecules
Built by:

* wiring together **other FBs**
* defining external event/data interfaces
* letting **event flow control execution**

No algorithms inside:

* behavior emerges from **connections**
* execution order comes from **event propagation**

(This is where IEC 61499 becomes very “hardware-like”).


### 5. Applications = circuits made of FBs

In other words, it is:
* a network of FB **instances**
* connected by event + data links

The paper says:
> designing like a **circuit board with ICs**

With compliant tools:

* FBs can be **distributed across devices**
* or across **multiple resources inside one device**

### 6. Resources = where things actually run

Resources are the **execution containers** and they:

* host FB instances
* map communication to SIFBs
* connect software to physical I/O
* synchronize execution via events
(the **workhorses** of the architecture.)

---
## section III

**what was actually fixed** in the **Second Edition** of IEC 61499, and *why*.
The big theme here is:

1. Too much was underspecified → different tools behaved differently → chaos.
2. Most of the **technical pain** was in **Execution Control**, especially **ECC semantics**.

---

### ECC semantics were ambiguous

Vendors interpreted ECC behavior differently, researchers argued endlessly, and same FB could behave differently on different runtimes => Make it **unambiguous** through three concrete fixes:

---
1. Only one input event at a time per FB: 
A **resource** must ensure that:

> **no more than one input event is delivered at any instant to a Function Block**

Before:

* Multiple events could arrive "at the same time"
* Multiple algorithms might activate **concurrently**
* =>:
  * race conditions.
  * non-repeatable behavior.
  * platform-dependent results.

After:
* Events are **serialized per FB**
* An FB processes **one event atomically**

The authors say "**more** deterministic", i.e.,

> *less nondeterministic than before*, not mathematically deterministic.

**I believe** it is because of that the first change:
* **does NOT guarantee system-wide determinism**
* **does NOT define scheduling**
* Only ensures:
  * *within one FB*, execution is not concurrent
---

2. Deterministic data sampling via **WITH**:
Previously:

* It was unclear **when data inputs were sampled**, thus, tools differed on: before, after event? or lazily?
* Same FB could read different data values on different platforms.

After:  
* When an input event is delivered,
* **all data inputs associated with that event (via WITH)** must be sampled together.

Let's say: 
* Event arrives,
* Snapshot of relevant data is taken,
* Algorithm runs on **that snapshot**.
Which leads to:
* Data-event coupling becomes **explicit**.
* Removes "Heisenbug" behavior in distributed systems.
(Note: a timing-sensitive bug that vanishes or mutates when trying to look at it, and ambiguous execution semantics are perfect breeding grounds for them).

---

3. Events are instantaneous, not Boolean flags

Perhaps, this is the **most subtle fix**, because of the confusion that in early PAS versions, events could behave like Boolean variables, but in the Standard, events are **instantaneous occurrences**

But ECC semantics didn't reflect that distinction, so, when an input event arrives:

1. Transition conditions are evaluated **once**
2. As soon as a transition fires, the event is considered **consumed**.
3. After entering a new state: event-based conditions are no longer valid, i.e., only event-less conditions may be evaluated

Without this:
* A single event could:

  * trigger multiple transitions
  * cause infinite loops
  * behave like a “sticky” signal

The example they mention (START <=> TRIGGERED) shows how this fix prevents recursive looping on a single event.

---

In general, ECCs suddenly matter more than expected, because ECCs were, originally, intended for **mode switching** (AUTO/MANUAL/etc.), whereas developers used ECCs as:

  * full-blown state machine languages.
  * control logic containers.
  * algorithm orchestrators.
Which increased usage demanded of stricter semantics, less ambiguity, and better readability.

And this is why the authrs explicitly compare ECC usage to **UML state machines**.

---

### Syntax & terminology cleanup

1. New **transition syntax** by introducing:

```
event_input_name[guard_condition]
```
With the purpose to 1. make **events vs data** visually distinct, 2. align with **UML notation**, 3. reduce misinterpretation

2. Terminology fix by replacing "clearing a transition"  with: a) "passing a transition"; (“clearing” sounded like a Boolean, which contradicted the **instantaneous event model**.

> They even admit this came from a **bad translation of GRAFCET** (`franchissement`) :(

---

### Priority ordering of transitions (Part 2 example)

1. Allow **explicit priority ordering** of transitions from a state, because when multiple transitions are enabled: a) order matters, b) Without defined priority => behavior diverges across tools.

This is shown as a **Part 2 tool capability**, not a core semantic change.

---

## TEMPORARY VARIABLES

They added **`VAR_TEMP`** inside **Basic FB algorithms**, explicitly aligned with **IEC 61131-3**.

That means in practice, we can declare **local variables inside an algorithm** but these variables:

  * exist **only during that algorithm execution**
  * are **created and initialized on each invocation**
  * **do not persist** between executions.
  * are **not visible outside** the algorithm.

Examples: loop counters, scratch variables, and intermediate computations.

Before this:

* developers were forced to declare such variables as **internal FB variables**
* that polluted FB state.
* and made ECC-driven excution harder to reason about.

After: improved **readability**, reduced **accidental state** and FBs become closer to sane programming practice

---

## NETWORK AND SEGMENT TYPES

- before: networks existed implicitly: there is "some Ethernet", "some bus", and communication assumptions were informal

=> tools could not: validate configurations, reason about compatibility or document system topology clearly,

- They added **segment types**, the latter describes: a network kind or protocol, its properties (bandwidth, semantics, etc.)

=> Tools can now provide **libraries of segment types**

- Devices can then declare: which **ports** they expose, and/or which **segment types** those ports can connect to

- In system configuration, links must connect compatible ports <=> segments, which enables:

* **structural validation** of configurations.
* clearer system documentation.
* the *possibility* (not guarantee) of:

  * automated network configuration.
  * communication performance analysis.

Here, we may consider that as laying groundwork, not enforcing timing.

---

## INTERACTION WITH PROGRAMMABLE CONTROLLERS (PLCs)

- Since IEC 61499 systems often:

* coexisted with legacy PLCs.
* don't replace them overnight :) =>

- They define **standard SIFBs** that act as **clients** of PLC services defined in **IEC 61131-5**, with concrete blocks:

* `READ` – sync PLC read
* `UREAD` – async PLC read
* `WRITE` – synch PLC write
* `TASK` – remotely trigger a PLC task.

This lets: a 61499 app **orchestrate** PLC logic without breaking encapsulation and using well-defined service interfaces

Again: integration, not domination.

---

## SIMPLIFIED "READ" AND "WRITE"

We may describe this as design-principle enforcement change, because, the First edition allowed **access paths**, i.e., READ/WRITE could reach into internal FB variables or internals of composite FBs.

But that:

* violated encapsulation.
* broke component boundaries.
* made refactoring dangerous.
* increased coupling and safety risks.

=> **Access paths are gone**, so READ/WRITE can access **only** FB/device/resource interfaces, while the internals are **hidden**, which enforces:

* true component orientation.
* safer systems.
* better maintainability.
* better analyzability.
* prevents "clever" hacks
* forces clean interface design.

---

## ADDITIONAL CHANGES AND CORRECTIONS

*things we should’ve had from the start.*

1. **RESET command for FB operational states**

* Before: lifecycle handling was incomplete / implicit.
* Now: an explicit **RESET** command exists.

=> predictable re-initialization, safer restart after faults, and cleaner state management in runtimes.

2. **Service sequences allowed for all FB types**
Call it: uniform expressiveness.

- Previously, service sequences (describing externally visible behavior over time) were limited to mainly SIFBs.

- fixed to **all FB types** can have service sequences, because:

* behavior can be documented consistently.
* external contracts become explicit.
* tools can reason better about interaction patterns.

3. **Adapters extended to basic FBs**

Call it architectural consistency fix.

- Before, adapters were only well-defined for **composite FBs**, i.e., basic FBs were second-class citizens :(


- The effectts of "basic FBs may also use adapters" is:
* cleaner interfaces.
* stronger decoupling.
* better reuse.
* fewer ad-hoc event/data bundles.

4. **Part 2 documentation updates**

* **IEC 61499-2** was updated to:

  * include informative examples of tool capabilities
  * update Document Type Definition **DTDs** to match Part 1 changes.
  (updating the XML grammar so software tools can correctly store, exchange, and validate models that use the new or clarified constructs introduced in Part 1.)


> This final section argues that IEC 61499’s success depends not on technical correctness but on achieving platform-scale adoption through interoperability, timing market entry correctly, and exploiting network effects—positioning 2012 as a critical window.


